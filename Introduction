Back in 1950, Alan Turing posed a now-famous question: Can machines think? His vision that artificial intelligence (AI) could one day become real was, at the time, a 
bold hypothesis—but over 70 years later, it is our reality (Kile, 2013). The journey from theory to reality has been gradual but persistent. In 1958, Frank Rosenblatt 
introduced the Mark I Perceptron, a machine that mimicked how the human brain processes patterns. It may have looked simple, but it laid the groundwork for decades of 
AI innovation. From the 1970s onward, interest in artificial intelligence grew steadily within academic circles. Major breakthroughs—from early expert systems to 
today’s deep learning architectures—signaled real progress. And yet, for decades, most people outside the tech world had little idea how fast AI was advancing behind 
the scenes. That all changed seemingly overnight in 2022, when ChatGPT launched. For the first time, AI felt personal. It wasn’t just something buried in research 
papers—it was answering our questions, writing our emails, and even helping kids with their homework. In 2023 alone, more than 120,000 academic papers related to AI 
were published (Singh et al., 2024), showing just how much attention the field now commands. Today, AI is no longer a tool of the future—it is a daily presence. In a 
friend’s home, I’ve seen lights, curtains, and appliances obey a single voice command. At school, students use AI to draft essays or solve equations. In taxis, 
self-driving systems silently map the road ahead. Online, AI doctors offer medical advice, and in nursing homes, robotic companions comfort the elderly. These aren’t 
isolated novelties; they are snapshots of a world where AI has become deeply entangled in how we live, learn, work, and age. But with all this convenience and 
capability, an uncomfortable question lingers: Are these changes truly good for us? Technology is meant to empower people—but is it quietly making us more passive? 
When an elderly person talks to a robot for comfort, is that innovation or a sign of social neglect? In Robot & Frank, a film discussed in Burton et al. (2017), a 
caregiving robot is designed to protect an elderly man’s health—but ends up helping him commit crimes. The robot follows its programmed priorities perfectly—but does 
so without any real understanding of morality or social impact. This raises deeper questions: What should AI value? Who decides what "good behavior" means for a 
machine? As AI grows more integrated into our lives, we can no longer treat it as just a tool—we must consider its role in society. In this report, I will explore the 
question: How should AIs behave in our society? Rather than trying to answer this in abstract terms, I will focus on the roles AI plays across different stages of 
human life—from education in childhood, to assistance in adulthood, to companionship in old age. By analyzing how AI can meaningfully support (but not replace) human 
needs, I aim to define what responsible, ethical AI behavior looks like in the real world.

(580 words)
